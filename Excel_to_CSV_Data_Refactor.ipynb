{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cd65a50",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Consolidación de Datos Demográficos por AGEB - Distrito Electoral 11, Puebla\n",
    "\n",
    "## **Propósito del Proyecto**\n",
    "\n",
    "Esta libreta tiene como objetivo **consolidar y procesar información demográfica de AGEBs (Áreas Geoestadísticas Básicas)** del Distrito Electoral Federal 11 de Puebla, preparando los datos para análisis electoral y estudios sociodemográficos.\n",
    "\n",
    "## **Contexto y Problemática**\n",
    "\n",
    "### **Desafío Principal:**\n",
    "- **No existe información pública oficial** que relacione directamente:\n",
    "  -  Datasets con **información electoral** (INE)\n",
    "  -  Datasets con **información demográfica** (INEGI)\n",
    "\n",
    "### **Solución Implementada:**\n",
    "- **Clasificación manual** de correspondencia geográfica entre:\n",
    "  - **Secciones electorales** del Distrito 11\n",
    "  - **AGEBs** con información demográfica\n",
    "- Proceso realizado **\"a ojo\"** utilizando mapas oficiales del **INE** e **INEGI**\n",
    "- Registro manual de qué secciones electorales se encuentran dentro de los límites geográficos de cada AGEB\n",
    "\n",
    "### **Desafío Técnico Adicional:**\n",
    "- **INEGI proporciona datasets separados** para cada AGEB individual\n",
    "- **Necesidad de reorganizar** toda la información en un **dataset único consolidado**\n",
    "\n",
    "---\n",
    "\n",
    "## **Procedimiento Implementado**\n",
    "\n",
    "### **1. Extracción y Consolidación de Datos**\n",
    "- **Lectura automática** de 123 archivos Excel individuales (uno por AGEB)\n",
    "- **Extracción de secciones electorales** contenidas en cada AGEB\n",
    "- **Consolidación** de todas las variables demográficas en un dataset único\n",
    "- **Normalización** de nombres de variables para consistencia\n",
    "\n",
    "### **2. Limpieza y Optimización del Dataset**\n",
    "- **Conversión a formato numérico** de todas las variables\n",
    "- **Eliminación de duplicados**: Remoción de columnas absolutas cuando existe la versión relativa\n",
    "- **Conservación selectiva** de variables absolutas importantes para análisis electoral\n",
    "- **Reducción dimensional**: De 683 variables iniciales a 355 variables optimizadas\n",
    "\n",
    "### **3. Tratamiento de Valores Faltantes**\n",
    "- **Imputación inteligente** basada en el contexto de cada variable:\n",
    "  - Variables demográficas específicas → `0` (ceros estructurales)\n",
    "  - Variables de carencias de servicios → `0` (ausencia probable)\n",
    "  - Variables generales → **mediana** (método robusto)\n",
    "\n",
    "---\n",
    "\n",
    "## **Resultado Final**\n",
    "\n",
    "**Dataset consolidado** con:\n",
    "- **122 AGEBs** del Distrito Electoral 11\n",
    "- **355 variables** demográficas optimizadas\n",
    "- **Correspondencia manual** con secciones electorales\n",
    "- **Datos completamente numéricos** listos para análisis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab3ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando librerias\n",
    "import os\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import unicodedata\n",
    "import re\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffff37ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de archivos Excel encontrados: 123\n"
     ]
    }
   ],
   "source": [
    "# Listar archivos Excel en DatosPorAGEB\n",
    "excel_files = [f for f in os.listdir('DatosPorAGEB') if f.endswith('.xlsx')]\n",
    "print(f\"Total de archivos Excel encontrados: {len(excel_files)}\")\n",
    "    \n",
    "# Variables para almacenar resultados\n",
    "todas_las_secciones = set()  # Usar set para evitar repeticiones\n",
    "archivos_con_secciones = []\n",
    "archivos_procesados = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "449fbde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#En esta celda se extraen las secciones de cada AGEB\n",
    "for file in excel_files:\n",
    "        try:\n",
    "            file_path = os.path.join('DatosPorAGEB', file)\n",
    "            xl = pd.ExcelFile(file_path)\n",
    "            archivos_procesados += 1\n",
    "            \n",
    "            # Buscar hojas que contengan información de secciones\n",
    "            for sheet in xl.sheet_names:\n",
    "                if 'seccion' in sheet.lower() or 'secciones' in sheet.lower():\n",
    "                    df_sheet = pd.read_excel(file_path, sheet_name=sheet)\n",
    "                    \n",
    "                    # Buscar columnas que puedan contener números de sección\n",
    "                    for col in df_sheet.columns:\n",
    "                        if 'seccion' in str(col).lower() or 'secc' in str(col).lower():\n",
    "                            # Extraer valores únicos de esa columna\n",
    "                            secciones_archivo = set(df_sheet[col].dropna().astype(str))\n",
    "                            todas_las_secciones.update(secciones_archivo)\n",
    "                            archivos_con_secciones.append(file)\n",
    "                            #print(f\"{file} - {sheet} - {col}: {len(secciones_archivo)} secciones\")\n",
    "                            break\n",
    "                    break\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error en {file}: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c20142fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Total de secciones únicas: 167\n",
      "Lista guardada en 'secciones_unicas.csv'\n"
     ]
    }
   ],
   "source": [
    "# Mostrar y guardar la lista completa de secciones\n",
    "if todas_las_secciones:\n",
    "    #print(f\"\\n LISTA COMPLETA DE SECCIONES SIN REPETICIONES:\")\n",
    "    print(\"=\" * 60)\n",
    "        \n",
    "    # Ordenar las secciones numéricamente si es posible\n",
    "    try:\n",
    "        secciones_ordenadas = sorted(list(todas_las_secciones), key=lambda x: int(x) if x.isdigit() else x)\n",
    "    except:\n",
    "        secciones_ordenadas = sorted(list(todas_las_secciones))\n",
    "        \n",
    "    print(f\"Total de secciones únicas: {len(secciones_ordenadas)}\")\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"\\nLista de secciones:\")\n",
    "\n",
    "    for i in range(0, len(secciones_ordenadas), 5):\n",
    "        fila = secciones_ordenadas[i:i+5]\n",
    "        numeros = [f\"{i+j+1:3d}.\" for j in range(len(fila))]\n",
    "        secciones = [f\"{seccion:>8}\" for seccion in fila]\n",
    "        print(\"  \".join([f\"{num} {sec}\" for num, sec in zip(numeros, secciones)]))\n",
    "    \"\"\" \n",
    "    # También guardar como CSV para uso posterior\n",
    "    df_secciones = pd.DataFrame({\n",
    "        'numero': range(1, len(secciones_ordenadas) + 1),\n",
    "        'seccion': secciones_ordenadas\n",
    "     })\n",
    "    df_secciones.to_csv('secciones_unicas.csv', index=False, encoding='utf-8')\n",
    "    print(f\"Lista guardada en 'secciones_unicas.csv'\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\n No se encontraron secciones en los archivos revisados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2e8f97",
   "metadata": {},
   "source": [
    "### Reorganizacion de los datos en un mismo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "813ec915",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalizar_nombre_variable(nombre):\n",
    "    \"\"\"\n",
    "    Normaliza el nombre de la variable: quita acentos, reemplaza ñ por n, elimina caracteres especiales,\n",
    "    y convierte a mayúsculas SIN aplicar abreviaturas.\n",
    "    \"\"\"\n",
    "    if not nombre or not isinstance(nombre, str):\n",
    "        return \"VAR_DESCONOCIDA\"\n",
    "    \n",
    "    # Quitar acentos\n",
    "    nombre = unicodedata.normalize('NFD', nombre)\n",
    "    nombre = nombre.encode('ascii', 'ignore').decode('utf-8')\n",
    "    \n",
    "    # Reemplazar ñ por n\n",
    "    nombre = nombre.replace('ñ', 'n').replace('Ñ', 'N')\n",
    "    \n",
    "    # Convertir a mayúsculas\n",
    "    nombre = nombre.upper()\n",
    "    \n",
    "    # Limpiar caracteres especiales\n",
    "    nombre = re.sub(r'[^A-Z0-9_]', '_', nombre)\n",
    "    nombre = re.sub(r'_+', '_', nombre)\n",
    "    nombre = nombre.strip('_')\n",
    "    \n",
    "    return nombre\n",
    "\n",
    "def extraer_secciones(workbook):\n",
    "    \"\"\"\n",
    "    Extrae los códigos de secciones de la hoja 'seccion'\n",
    "    \"\"\"\n",
    "    secciones = []\n",
    "    if 'seccion' in workbook.sheetnames:\n",
    "        ws = workbook['seccion']\n",
    "        for row in ws.iter_rows(min_row=2, values_only=True):\n",
    "            if row[0] and str(row[0]).strip():\n",
    "                secciones.append(str(row[0]).strip())\n",
    "    return secciones\n",
    "\n",
    "def es_valor_valido(valor):\n",
    "    \"\"\"\n",
    "    Verifica si un valor es válido (no None, no vacío, no string vacío)\n",
    "    \"\"\"\n",
    "    if valor is None:\n",
    "        return False\n",
    "    if isinstance(valor, str) and valor.strip() == '':\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def extraer_indicadores(workbook):\n",
    "    \"\"\"\n",
    "    Extrae indicadores de todas las hojas excepto 'seccion'\n",
    "    Aplica la lógica específica para columnas absolutas/relativas:\n",
    "    - Si ambas columnas existen y tienen datos válidos: crear dos columnas con sufijos _ABSOLUTO y _RELATIVO\n",
    "    - Si solo una columna existe o tiene datos válidos: crear una columna sin sufijo\n",
    "    \"\"\"\n",
    "    indicadores = {}\n",
    "    \n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        if sheet_name.lower() != 'seccion':\n",
    "            ws = workbook[sheet_name]\n",
    "            \n",
    "            # Buscar la fila que contiene \"Indicador\", \"Absoluto\", \"Relativo\"\n",
    "            fila_encabezados = None\n",
    "            for row_num, row in enumerate(ws.iter_rows(values_only=True), 1):\n",
    "                if row and any('indicador' in str(cell).lower() if cell else False for cell in row):\n",
    "                    fila_encabezados = row_num\n",
    "                    break\n",
    "            \n",
    "            if fila_encabezados:\n",
    "                # Extraer datos desde la siguiente fila hasta la penúltima\n",
    "                for row_num in range(fila_encabezados + 1, ws.max_row):\n",
    "                    row = list(ws.iter_rows(min_row=row_num, max_row=row_num, values_only=True))[0]\n",
    "                    \n",
    "                    if row and row[0] and str(row[0]).strip():\n",
    "                        nombre_indicador = str(row[0]).strip()\n",
    "                        valor_absoluto = row[1] if len(row) > 1 else None\n",
    "                        valor_relativo = row[2] if len(row) > 2 else None\n",
    "                        \n",
    "                        # Normalizar nombre del indicador\n",
    "                        nombre_normalizado = normalizar_nombre_variable(nombre_indicador)\n",
    "                        \n",
    "                        # Verificar validez de valores\n",
    "                        abs_valido = es_valor_valido(valor_absoluto)\n",
    "                        rel_valido = es_valor_valido(valor_relativo)\n",
    "                        \n",
    "                        # Aplicar lógica según especificaciones del usuario\n",
    "                        if abs_valido and rel_valido:\n",
    "                            # Ambos valores válidos: crear dos columnas con sufijos\n",
    "                            indicadores[f\"{nombre_normalizado}_ABSOLUTO\"] = valor_absoluto\n",
    "                            indicadores[f\"{nombre_normalizado}_RELATIVO\"] = valor_relativo\n",
    "                        elif abs_valido and not rel_valido:\n",
    "                            # Solo absoluto válido: crear columna sin sufijo\n",
    "                            indicadores[nombre_normalizado] = valor_absoluto\n",
    "                        elif not abs_valido and rel_valido:\n",
    "                            # Solo relativo válido: crear columna sin sufijo\n",
    "                            indicadores[nombre_normalizado] = valor_relativo\n",
    "                        # Si ninguno es válido, no agregar nada\n",
    "    \n",
    "    return indicadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33a47f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def procesar_archivos_excel():\n",
    "    \"\"\"\n",
    "    Procesa todos los archivos Excel en la carpeta DatosPorAGEB\n",
    "    \"\"\"\n",
    "    carpeta = \"DatosPorAGEB\"\n",
    "    datos_consolidados = []\n",
    "    \n",
    "    # Procesar cada archivo Excel\n",
    "    for archivo in os.listdir(carpeta):\n",
    "        if archivo.endswith('.xlsx'):\n",
    "            ruta_archivo = os.path.join(carpeta, archivo)\n",
    "            #print(f\"Procesando: {archivo}\")\n",
    "            \n",
    "            try:\n",
    "                workbook = load_workbook(ruta_archivo, data_only=True)\n",
    "                \n",
    "                # Extraer código AGEB del nombre del archivo\n",
    "                ageb_code = archivo.replace('.xlsx', '')\n",
    "                \n",
    "                # Extraer indicadores\n",
    "                indicadores = extraer_indicadores(workbook)\n",
    "                \n",
    "                # Extraer secciones\n",
    "                secciones = extraer_secciones(workbook)\n",
    "                \n",
    "                # Crear fila de datos\n",
    "                fila_datos = {'AGEB': ageb_code}\n",
    "                fila_datos.update(indicadores)\n",
    "                \n",
    "                # Agregar información de secciones\n",
    "                if secciones:\n",
    "                    fila_datos['SECCIONES_CONTENIDAS'] = ';'.join(secciones)\n",
    "                    fila_datos['NUM_SECCIONES'] = len(secciones)\n",
    "                else:\n",
    "                    fila_datos['SECCIONES_CONTENIDAS'] = ''\n",
    "                    fila_datos['NUM_SECCIONES'] = 0\n",
    "                \n",
    "                datos_consolidados.append(fila_datos)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando {archivo}: {e}\")\n",
    "    \n",
    "    return datos_consolidados\n",
    "\n",
    "def guardar_resultados(datos_consolidados):\n",
    "    \"\"\"\n",
    "    Guarda los resultados en archivo CSV\n",
    "    \"\"\"\n",
    "    # Guardar datos consolidados\n",
    "    if datos_consolidados:\n",
    "        with open('AGEB_Consolidado_Completo.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=datos_consolidados[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(datos_consolidados)\n",
    "        \n",
    "        print(f\"Archivo consolidado guardado: AGEB_Consolidado_Completo.csv\")\n",
    "        print(f\"Total de AGEBs procesados: {len(datos_consolidados)}\")\n",
    "        #print(f\"Total de variables: {len(datos_consolidados[0]) - 1}\")  # -1 por AGEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d1e75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando procesamiento completo de archivos AGEB...\n",
      "Archivo consolidado guardado: AGEB_Consolidado_Completo.csv\n",
      "Total de AGEBs procesados: 123\n",
      "Procesamiento completado.\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando procesamiento completo de archivos AGEB...\")\n",
    "datos = procesar_archivos_excel()\n",
    "guardar_resultados(datos)\n",
    "print(\"Procesamiento completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094755c4",
   "metadata": {},
   "source": [
    "### Limpieza del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ae7b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('AGEB_Consolidado_Completo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8342500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todas las columnas excepto 'AGEB'\n",
    "columnas_numericas = [col for col in new_df.columns if col != 'AGEB']\n",
    "\n",
    "# Convertir cada columna a float, los strings se convertirán automáticamente a NaN\n",
    "for col in columnas_numericas:\n",
    "    new_df[col] = pd.to_numeric(new_df[col], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2daf5aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminando SECCIONES_CONTENIDAS\n",
    "new_df = new_df.drop(columns=['SECCIONES_CONTENIDAS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c9d4c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droppeando columnas con mas del 50% de datos nulos\n",
    "new_df = new_df.dropna(axis=1, thresh=0.5*len(new_df))\n",
    "#Droppeando rows con mas del 50% de datos nulos\n",
    "new_df = new_df.dropna(axis=0, thresh=0.5*len(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42935c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#viendo top 10 rows con mas nulos\n",
    "#new_df.isnull().sum(axis=1).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5d6124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#viendo top 10 columnas con mas nulos\n",
    "#new_df.isnull().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0509698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_columnas_absolutas_duplicadas(df):\n",
    "    \"\"\"\n",
    "    Elimina columnas con valores absolutos cuando existe también su versión relativa,\n",
    "    conservando solo las columnas absolutas especificadas como excepciones.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame de pandas\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con columnas absolutas duplicadas eliminadas\n",
    "    \"\"\"\n",
    "    # Columnas absolutas que se deben conservar siempre\n",
    "    conservar_absolutos = [\n",
    "        'ELECTORAL_TOTAL_VOTOS',\n",
    "        'ELECTORAL_LISTA_NOMINAL',\n",
    "        'GRADO_PROMEDIO_DE_ESCOLARIDAD',\n",
    "        'EDAD_MEDIANA_DE_LA_POBLACION_TOTAL'\n",
    "    ]\n",
    "    \n",
    "    # Hacer una copia para no modificar el original\n",
    "    df_limpio = new_df.copy()\n",
    "    \n",
    "    # Encontrar todas las columnas que terminan en \"_ABSOLUTO\"\n",
    "    columnas_absolutas = [col for col in df_limpio.columns if col.endswith('_ABSOLUTO')]\n",
    "    \n",
    "    columnas_a_eliminar = []\n",
    "    \n",
    "    for col_absoluta in columnas_absolutas:\n",
    "        # Generar el nombre de la columna relativa correspondiente\n",
    "        base_name = col_absoluta.replace('_ABSOLUTO', '')\n",
    "        col_relativa = base_name + '_RELATIVO'\n",
    "        \n",
    "        # Si existe la versión relativa y no está en la lista de conservar\n",
    "        if col_relativa in df_limpio.columns and col_absoluta not in conservar_absolutos:\n",
    "            columnas_a_eliminar.append(col_absoluta)\n",
    "            #print(f\"Eliminando: {col_absoluta} (existe versión relativa)\")\n",
    "        #elif col_absoluta in conservar_absolutos:\n",
    "            #print(f\"Conservando: {col_absoluta} (en lista de excepciones)\")\n",
    "    \n",
    "    # Eliminar las columnas identificadas\n",
    "    df_limpio = df_limpio.drop(columns=columnas_a_eliminar)\n",
    "    \n",
    "\n",
    "    print(f\"- Columnas absolutas encontradas: {len(columnas_absolutas)}\")\n",
    "    print(f\"- Columnas absolutas eliminadas: {len(columnas_a_eliminar)}\")\n",
    "    print(f\"- Columnas absolutas conservadas: {len(columnas_absolutas) - len(columnas_a_eliminar)}\")\n",
    "    print(f\"- Total de columnas después de limpieza: {len(df_limpio.columns)}\")\n",
    "    \n",
    "    return df_limpio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "681c2efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Columnas absolutas encontradas: 328\n",
      "- Columnas absolutas eliminadas: 328\n",
      "- Columnas absolutas conservadas: 0\n",
      "- Total de columnas después de limpieza: 355\n"
     ]
    }
   ],
   "source": [
    "df_limpio = eliminar_columnas_absolutas_duplicadas(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f993edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_e_imputar_dataset(df):\n",
    "    \"\"\"\n",
    "    Función concisa para limpiar dataset y aplicar imputación inteligente\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    # Imputación inteligente y concisa\n",
    "    # Variables que deben ser 0 cuando falta (grupos muy específicos)\n",
    "    cero_patterns = ['85_anos', 'lengua_indigena', 'afromexicana', 'afrodescendiente', \n",
    "                     'pemex', 'bienestar', 'otra_institucion', 'colectivas']\n",
    "    \n",
    "    # Variables de vivienda sin servicios (probable que sea 0)\n",
    "    sin_servicios = ['sin_ningun_bien', 'no_disponen', 'piso_de_tierra', \n",
    "                     'solo_un_cuarto', 'sin_tecnologias', 'sin_radio', 'sin_linea']\n",
    "    \n",
    "    for col in df_clean.select_dtypes(include=[np.number]).columns:\n",
    "        col_lower = col.lower()\n",
    "        \n",
    "        # Estrategia 1: Ceros estructurales\n",
    "        if any(pattern in col_lower for pattern in cero_patterns + sin_servicios):\n",
    "            df_clean[col] = df_clean[col].fillna(0)\n",
    "        \n",
    "        # Estrategia 2: Mediana para el resto\n",
    "        else:\n",
    "            mediana = df_clean[col].median()\n",
    "            df_clean[col] = df_clean[col].fillna(mediana)\n",
    "    \n",
    "    # 3. Reporte\n",
    "    nulos_inicial = df.isnull().sum().sum()\n",
    "    nulos_final = df_clean.isnull().sum().sum()\n",
    "    \n",
    "    print(f\" Nulos eliminados: {nulos_inicial:,} → {nulos_final:,}\")\n",
    "    print(f\" Dataset final: {df_clean.shape[0]} filas × {df_clean.shape[1]} columnas\")\n",
    "    print(f\" {df_clean.select_dtypes(include=[np.number]).shape[1]} variables numéricas\")\n",
    "    \n",
    "    return df_clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb53a19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Nulos eliminados: 930 → 0\n",
      " Dataset final: 122 filas × 355 columnas\n",
      " 354 variables numéricas\n"
     ]
    }
   ],
   "source": [
    "df_limpio = limpiar_e_imputar_dataset(df_limpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "371cf1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardando el df limpio\n",
    "df_limpio.to_csv('AGEB_Consolidado_Completo.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analisis_electoral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
